{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we briefly introduce two approaches for parallel computing in Python: `ipyparallel` and `mpi4py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "- [Why parallelize Python code?](#Why-would-you-want-to-do-parallel-programming-in-Python?)\n",
    "    - [Before parallelizing Python code](#Before-spending-a-lot-of-time-parallelizing-your-Python-code)\n",
    "- [Global interpreter lock](#The-global-interpreter-lock-(GIL))\n",
    "- [IPython for parallel computing](#IPython-for-parallel-computing)\n",
    "    - [Configuration](#Configuration)\n",
    "    - [Using `ipyparallel`](#using_ipyparallel)\n",
    "    - [Parallel magic commands](#Parallel-magic-commands)\n",
    "    - [Example problem](#Example-problem:-Computing-the-Mandelbrot-set)\n",
    "- [MPI4Py](#MPI4Py)\n",
    "    - [MPI4Py basics](#MPI4Py-basics)\n",
    "    - [Parallelization via MPI4Py](#Parallelization-via-MPI4Py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Many resources on parallel Python exist on the web, and some have been used as inspiration for the material presented here. In particular, the following resources are recommended:\n",
    "> - https://github.com/dvalters/RSE18-Python-Parallel-workshop\n",
    "> - https://nbviewer.jupyter.org/github/CQuIC/summer17-computing-workshop/blob/master/Parallelization/mpi4py/Introduction_to_MPI4py.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why would you want to do parallel programming in Python? \n",
    "\n",
    "Traditionally, Python is considered to not support parallel programming very well, and \"proper\" parallel programming should be left to \"heavy-duty\" languages such as Fortran or C/C++ where libraries or standards such as OpenMP and MPI can be utilised. \n",
    "\n",
    "For large scale, massively-parallel applications, this is probably still the case, but a rich variety of libraries and packages have been developed outside the core Python language, so parallel programming is now much better supported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before spending a lot of time parallelizing your Python code\n",
    "- If your Python code is running too slow, there are many ways to speed it up:\n",
    "    - Begin by identifying the performance bottlenecks in the code - **profile before optimizing!**\n",
    "    - Use fast numerical packages like [Numpy](http://www.numpy.org/).\n",
    "    - Use a just-in-time (JIT) compiler like [Numba](https://numba.pydata.org/).\n",
    "    - Use C-extensions from [Cython](http://cython.org/).\n",
    "    - Rewrite the performance-critical functions in C/C++/Fortran, and import them into Python.\n",
    "    - Any of these methods could speed up Python code by orders of magnitude!\n",
    "- So why bother with parallelizing Python?\n",
    "    - Perhaps you're already using Numpy, Numba, Cython and/or C/C++/Fortran for the most compute-intensive parts of your code.\n",
    "    - Perhaps you have a problem that is particularly suitable for parallelization, e.g. a large dataset that can be processed independently in chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The global interpreter lock (GIL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The most common implementation of Python (interpreter/executable that runs your Python code) is called CPython.\n",
    "- CPython doesn't support using threads well, because it's been written to assume that individual Python programs are serial.\n",
    "- CPython implements something called the Global Interpreter Lock (GIL) that protects access to Python objects, preventing multiple threads executing Python bytecode through the Python interpreter at once.\n",
    "- Subsequent developments in Python have come to rely on the GIL being present, so removing it in future versions of Python is unlikely.\n",
    "- Parallel approaches to Python are normally based around running multiple instances of the Python interpreter, each with its own copy of the the code being run and each with its own separate GIL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPython for parallel computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IPython abstracts out parallelism in a general way, supporting many different styles of parallelism: Single program multiple data (SPMD) and multiple program multiple data (MPMD) parallelism, message passing using MPI, task farming, data parallel, a combinations of approaches or custom user-defined approaches.\n",
    "\n",
    "Most importantly, IPython and the `ipyparallel` package enables all types of parallel applications to be developed, executed, debugged, and monitored *interactively*.\n",
    "\n",
    "The following are some example use cases:\n",
    "\n",
    "- Quickly parallelize algorithms that are embarrassingly parallel using a number of simple approaches. Many simple things can be parallelized interactively in one or two lines of code.\n",
    "- Steer traditional MPI applications on a supercomputer from an IPython session on your laptop.\n",
    "- Analyze and visualize large datasets (that could be remote and/or distributed) interactively using IPython and tools like matplotlib.\n",
    "- Develop, test and debug new parallel algorithms (that may use MPI) interactively.\n",
    "- Tie together multiple MPI jobs running on different systems into one giant distributed and parallel system.\n",
    "- Run a set of tasks on a set of CPUs using dynamic load balancing.\n",
    "\n",
    "> Adapted from the [official documentation](https://ipyparallel.readthedocs.io/en/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already done with jupyter notebook setup, via command `ipython profile create`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='using_ipyparallel'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `ipyparallel`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting an IPython cluster for parallel computing can be done from inside Jupyter: \n",
    "- Go to the Jupyter dashboard \n",
    "- Click the \"IPython clusters\" tab \n",
    "- Choose number of engines (e.g. 4), and click \"Start\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interacting with the engines is done via the `ipyparallel.Client()` method:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "client = ipp.Client()\n",
    "print(\"Number of ipyparallel engines:\", len(client.ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Direct view\n",
    "\n",
    "The direct view represents one way of working with IPython engines where the capabilities of each engine are directly and explicitly exposed to the user.\n",
    "\n",
    "We construct a `DirectView` object via list-access to the client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dview = client[:]\n",
    "print(dview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to calculate the square of 10 integers. We can first define a function and then calculate the squares serially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(x):\n",
    "    return x*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = [square(x) for x in range(1,11)]\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `ipyparallel` it is handy to do this via `map_sync`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = dview.map_sync(square, range(1,11))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax for `map_sync` is straightforward - it accepts the function and a list of input arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load balanced view\n",
    "\n",
    "The load balanced view is appropriate when you have many jobs that take differnet amounts of time to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lview = client.load_balanced_view()\n",
    "print(lview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "lview.map_sync(lambda x: sum(x), np.random.random((10, 100000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel magic commands\n",
    "\n",
    "The simplest way to use `ipyparallel` is via the `%px` magic command, which executes code in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%px import os\n",
    "%px a = os.getpid()\n",
    "%px print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the %px magic together with `scatter` and `gather` functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dview.scatter('xs', range(24))\n",
    "%px y = [x**2 for x in xs]\n",
    "%px print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(dview.gather('y').get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example problem: Computing the Mandelbrot set\n",
    "\n",
    "We will now look at a more compute intensive problem and measure the speedup from using the `@parallel` decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serial version\n",
    "def mandel1(x, y, max_iters=80):\n",
    "    c = complex(x, y)\n",
    "    z = 0.0j\n",
    "    for i in range(max_iters):\n",
    "        z = z*z + c\n",
    "        if z.real*z.real + z.imag*z.imag >= 4:\n",
    "            return i\n",
    "    return max_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel version using the @parallel decorator\n",
    "@dview.parallel(block = True)\n",
    "def mandel2(x, y, max_iters=80):\n",
    "    c = complex(x, y)\n",
    "    z = 0.0j\n",
    "    for i in range(max_iters):\n",
    "        z = z*z + c\n",
    "        if z.real*z.real + z.imag*z.imag >= 4:\n",
    "            return i\n",
    "    return max_iters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize arrays and meshgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-2, 1, 0.01)\n",
    "y = np.arange(-1, 1, 0.01)\n",
    "X, Y = np.meshgrid(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "im1 = np.reshape(list(map(mandel1, X.ravel(), Y.ravel())), \n",
    "                 (len(y), len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "im2 = np.reshape(mandel2.map(X.ravel(), Y.ravel()),  (len(y), len(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "axes[0].grid(False)\n",
    "axes[0].imshow(im1, cmap='jet')\n",
    "axes[1].grid(False)\n",
    "axes[1].imshow(im2, cmap='jet')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MPI4Py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MPI, the Message Passing Interface, is a standard for parallel programming involving communication between separate parallel processes each with their own separate memory allocation. MPI processes have to pass messages between themselves to invoke code execution and share data between with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MPI4Py basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With MPI4Py, it is convenient to obtain the basic MPI settings including the communicator, the rank of the process, and the number of processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MPI4Py also provides convenient communicating functions like `send`, `recv`, `scatter`, `gather`, etc.\n",
    "\n",
    "There's no automatic mapping but you may find `scatter` and `gather` very useful in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exercise36'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelization via MPI4Py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example code of calculating the distances via `mpi4py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from mpi4py import MPI\n",
    "\n",
    "import dist_cities as dc\n",
    "\n",
    "# MPI settings\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "nprocs = comm.Get_size()\n",
    "\n",
    "# prepare data and determine workloads\n",
    "\n",
    "if rank == 0:\n",
    "    cities = dc.read_cities()\n",
    "    coord_pairs = dc.create_coord_pairs(cities)\n",
    "    npairs = len(coord_pairs)\n",
    "\n",
    "    dn = npairs // nprocs\n",
    "    if npairs % nprocs != 0:\n",
    "        dn += 1\n",
    "\n",
    "# compute via MPI\n",
    "# 1. Slice coord_pairs for processes\n",
    "# 2. Scatter the sliced pieces\n",
    "# 3. Do computation on each process\n",
    "# 4. Gather results to master process\n",
    "# 5. Collect the results into one list\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "if rank == 0:\n",
    "    data = [coord_pairs[int(x*dn):int((x+1)*dn)] for x in range(nprocs)]\n",
    "else:\n",
    "    data = None\n",
    "\n",
    "data = comm.scatter(data, root=0)\n",
    "\n",
    "result = [dc.calc_dist(p) for p in data]\n",
    "\n",
    "result = comm.gather(result, root=0)\n",
    "\n",
    "if rank == 0:\n",
    "    output = []\n",
    "    for a in result:\n",
    "        output += a\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "if rank == 0:\n",
    "    print(\"Maximum distance: %.0f km\" % max(output))\n",
    "    print(\"Computing time: %.3f sec\" % (t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
